{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCnQiRM7ph_N"
      },
      "source": [
        "Sequential Text Semantics Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xWGLH53pdzj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRNGGpsqpdxQ"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('IMDB Dataset Preprocessed - 100K.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOqlB3ntpdrh"
      },
      "outputs": [],
      "source": [
        "# Define the SVM gradient function\n",
        "def svm_grad(w, X, y, reg):\n",
        "    margin = y * np.dot(X, w) # calculate margin of sample using dot prod. of X and w\n",
        "    misclassified = margin < 1\n",
        "    grad = np.zeros_like(w) # init. gradient vectors as all zeros\n",
        "    grad += reg * 2 * w # overfitting rokega by penalizing large weights\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    grad -= np.mean(X[misclassified] * y[misclassified, np.newaxis].astype(float), axis=0) # basically finds the best hyperplane by subtracting mean of misclassified samples from gradient\n",
        "    return grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgQuifMtpdpP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "print(data.shape)\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['sentiment'], test_size=0.4, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90n2xDo2pdmL"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.astype(str)\n",
        "X_test = X_test.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibUxLV8Spdjh"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Convert the reviews into feature vectors\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000) # removes eng. stop words (\"a\", \"the\", '\"and\") and top 1000 most freq. words based on their occurence\n",
        "X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test = vectorizer.transform(X_test).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVkzn3HApdg2"
      },
      "outputs": [],
      "source": [
        "# Convert the labels into integers , assigns 'positive' val. of 1 and 'negative' val. of -1\n",
        "y_train = (y_train == 'positive').astype(int) * 2 - 1\n",
        "y_test = (y_test == 'positive').astype(int) * 2 - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGHGwIC5pdGJ"
      },
      "outputs": [],
      "source": [
        "# Initialize the weights\n",
        "w = np.zeros(X_train.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2axTXJRvejb"
      },
      "outputs": [],
      "source": [
        "# Set the hyperparameters\n",
        "reg = 1e-5            # regularization param. jitna chota hoga utna ziada complex model and behtar accuracy\n",
        "learning_rate = 0.01  # determines the step size the algo takes to converge to optimal soln.\n",
        "num_iterations = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBORFSVZveVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a293ad0a-033d-4ce3-e8c4-ca65c720c019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average execution time: 0.43814740681648257\n",
            "Total time: 438.14740681648254\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# trains SVM using grad. descent\n",
        "for i in range(num_iterations):\n",
        "    gradient = svm_grad(w, X_train, y_train, reg)\n",
        "    w -= learning_rate * gradient # determines size of weight update in each iteration\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print('Average execution time: {}'.format(total_time / 1000))\n",
        "print('Total time: {}'.format(total_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qss9XikveNR"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_pred = np.sign(np.dot(X_test, w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvOnvywWvk_H"
      },
      "outputs": [],
      "source": [
        "# Calculate evaluation metrics\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "precision = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_pred == 1)\n",
        "recall = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_test == 1)\n",
        "f1_score = 2 * precision * recall / (precision + recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASea8dqKvmve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a514326-651c-46d3-ea8a-f9caacc0ae8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8364968102701426\n",
            "Precision: 0.8202594659828029\n",
            "Recall: 0.8600917431192661\n",
            "F1-score: 0.8397034977993978\n"
          ]
        }
      ],
      "source": [
        "# Print the evaluation metrics\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1-score:', f1_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gaX_qb75YMo"
      },
      "source": [
        "CUDA Text Semantics Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHB0xrgYv-Bk"
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "import numba\n",
        "from numba import types\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKOnP1laj88L"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('IMDB Dataset Preprocessed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bZuT46t5lyR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['sentiment'], test_size=0.4, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVf-5ISp5lrK"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.astype(str)\n",
        "X_test = X_test.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfIS-pA25ldw"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Convert the reviews into feature vectors\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "X_train = X_train.astype(float)\n",
        "X_test = X_test.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ohYtzg8GjtP"
      },
      "outputs": [],
      "source": [
        "# Convert the labels into integers\n",
        "y_train = (y_train == 'positive').astype(int) * 2 - 1\n",
        "y_test = (y_test == 'positive').astype(int) * 2 - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yTOL6eW1Rf6"
      },
      "outputs": [],
      "source": [
        "# Set the hyperparameters\n",
        "w2 = np.zeros(X_train.shape[1])\n",
        "reg2 = 1e-5\n",
        "learning_rate2 = 0.01\n",
        "num_iterations2 = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTHYs06avpji"
      },
      "outputs": [],
      "source": [
        "import numba\n",
        "from numba import cuda\n",
        "@numba.cuda.jit\n",
        "def svm_grad2_kernel(w, X, y, result, margin):\n",
        "    tx = cuda.threadIdx.x # this is the unique thread ID within a 1D block\n",
        "    ty = cuda.blockIdx.x  # Similarly, this is the unique block ID within the 1D grid\n",
        "\n",
        "    block_size = cuda.blockDim.x  # number of threads per block\n",
        "    grid_size = cuda.gridDim.x    # number of blocks in the grid\n",
        "    g = cuda.cg.this_grid()\n",
        "\n",
        "    start = tx + ty * block_size\n",
        "    stride = block_size * grid_size\n",
        "\n",
        "    for j in range(start, len(X), stride):\n",
        "        margin[j] = 0.0\n",
        "        for k in range(len(X[j])):\n",
        "            margin[j] += X[j][k] * w[k]\n",
        "        margin[j] *= y[j]\n",
        "        if margin[j] < 1:\n",
        "            result[j] = True\n",
        "        else:\n",
        "            result[j] = False\n",
        "    g.sync()\n",
        "\n",
        "@numba.cuda.jit\n",
        "def svm_grad2_kernel2(w, reg, grad):\n",
        "    tx = cuda.threadIdx.x # this is the unique thread ID within a 1D block\n",
        "    ty = cuda.blockIdx.x  # Similarly, this is the unique block ID within the 1D grid\n",
        "\n",
        "    block_size = cuda.blockDim.x  # number of threads per block\n",
        "    grid_size = cuda.gridDim.x    # number of blocks in the grid\n",
        "    g = cuda.cg.this_grid()\n",
        "\n",
        "    start = tx + ty * block_size # to traverse each thread in a block\n",
        "    stride = block_size * grid_size\n",
        "\n",
        "    for j in range(start, len(grad), stride):\n",
        "      grad[j] += w[j]\n",
        "    g.sync()\n",
        "\n",
        "@numba.cuda.jit #ADDED THIS PART AFTER RUNTIME EXPIRED\n",
        "def svm_grad2_kernel3(grad, mean):\n",
        "    tx = cuda.threadIdx.x # this is the unique thread ID within a 1D block\n",
        "    ty = cuda.blockIdx.x  # Similarly, this is the unique block ID within the 1D grid\n",
        "\n",
        "    block_size = cuda.blockDim.x  # number of threads per block\n",
        "    grid_size = cuda.gridDim.x    # number of blocks in the grid\n",
        "    g = cuda.cg.this_grid()\n",
        "\n",
        "    start = tx + ty * block_size # to traverse each thread in a block\n",
        "    stride = block_size * grid_size\n",
        "\n",
        "    for j in range(start, len(grad), stride):\n",
        "        grad[j] -= mean[j]\n",
        "    g.sync()\n",
        "\n",
        "def svm_grad2(w, X, y, reg):\n",
        "    grad = np.empty(len(w), dtype=np.float32)\n",
        "    result = np.empty((len(X),), dtype=np.bool_)\n",
        "    margin = np.empty((len(X),), dtype=np.float32)\n",
        "    threadsperblock = 128\n",
        "    blockspergrid = (len(X) + threadsperblock - 1) // threadsperblock\n",
        "\n",
        "    d_w = cuda.to_device(w)\n",
        "    d_X = cuda.to_device(X)\n",
        "    d_y = cuda.to_device(y)\n",
        "    d_grad = cuda.to_device(grad)\n",
        "    d_reg = cuda.to_device(reg)\n",
        "    d_margin = cuda.to_device(margin)\n",
        "\n",
        "    d_result = cuda.to_device(result)\n",
        "\n",
        "    svm_grad2_kernel[blockspergrid, threadsperblock](d_w, d_X, d_y, d_result, d_margin)\n",
        "    cuda.synchronize()\n",
        "\n",
        "    d_result.copy_to_host(result)\n",
        "\n",
        "    blockspergrid2 = (len(w) + threadsperblock - 1) // threadsperblock #changed this after runtime expired\n",
        "    Wnew = reg * 2.0 * (w.astype(np.float64))\n",
        "\n",
        "    d_Wnew = cuda.to_device(Wnew)\n",
        "\n",
        "    svm_grad2_kernel2[blockspergrid2, threadsperblock](d_Wnew, d_reg, d_grad) #put blockspergrid2 here\n",
        "    cuda.synchronize()\n",
        "\n",
        "    d_grad.copy_to_host(grad)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    mean = np.mean(X[result] * y[result, np.newaxis].astype(float), axis=0) #AFTER RUNTIME EXPIRED\n",
        "\n",
        "    d_mean = cuda.to_device(mean) #AFTER RUNTIME EXPIRED\n",
        "\n",
        "    blockspergrid3 = (len(mean) + threadsperblock - 1) // threadsperblock #changed this after runtime expired\n",
        "    svm_grad2_kernel3[blockspergrid3, threadsperblock](d_grad, d_mean)\n",
        "    cuda.synchronize()\n",
        "    d_grad.copy_to_host(grad)\n",
        "\n",
        "    #grad -= np.mean(X[result] * y[result, np.newaxis].astype(float), axis=0) #Remove # if kernel3 doesn't work\n",
        "\n",
        "    return grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oftNOrf74OOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5abc90-5dba-4858-8049-0e74f16da080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 8 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 8 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average execution time: 0.28316290283203127\n",
            "Total time: 283.16290283203125\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "# Train the SVM model using gradient descent\n",
        "for i in range(num_iterations2):\n",
        "    grad1 = svm_grad2(w2, X_train, y_train, reg2)\n",
        "    w2 -= learning_rate2 * grad1\n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print('Average execution time: {}'.format(total_time / 1000))\n",
        "print('Total time: {}'.format(total_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz7zKM1Hv9ur"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_pred = np.sign(np.dot(X_test, w2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHa6fstEv9sD"
      },
      "outputs": [],
      "source": [
        "# Calculate evaluation metrics\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "precision = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_pred == 1)\n",
        "recall = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_test == 1)\n",
        "f1_score = 2 * precision * recall / (precision + recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8GrDQb0v9pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6c3448-eb31-4100-ceaf-79bc02630a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7964\n"
          ]
        }
      ],
      "source": [
        "# Print the evaluation metrics\n",
        "print('Accuracy:', accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}